<!DOCTYPE html>
<html lang="en">
<head>
<!-- 2019-10-29 Tue 14:32 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>使用神经网络训练CIFAR-10</title>
<meta name="generator" content="Org mode">
<meta name="author" content="luhuaei">

<meta name="google-site-verification" content="dVWCUwH8eYXavYgAUJtgmzwlXVIcYZeyvlUolZQVb2E" />
<link rel="stylesheet" type="text/css" href="/assets/css/style.css"/>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async></script>
<link rel="shortcut icon" type="image/x-icon" href="favicon.ico">
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div class="content-wrapper container">
   <div class="row"> <div class="col"> </div>   <div class="col-sm-6 col-md-8">
<div id="preamble" class="status">

<div class="">
    <a href="/"> Luhua.ei </a>
</div>
<ul class="">
  <li><a href="/about.html"> About Me </a> </li>
  <li><a href="https://github.com/luhuaei"> Github </a> </li>
  <li><a href="/archive.html"> Posts </a> </li>
</ul>
  <hr>
</div>
<div id="content">
<header>
<h1 class="title">使用神经网络训练CIFAR-10</h1>
</header>
<div id="outline-container-org14e4035" class="outline-2">
<h2 id="org14e4035">激励函数</h2>
<div class="outline-text-2" id="text-org14e4035">
</div>
<div id="outline-container-org9129f88" class="outline-3">
<h3 id="org9129f88">为什么需要激励函数？</h3>
<div class="outline-text-3" id="text-org9129f88">
<p>
因为在现实中，有很多的数据都不是可以使用一个线或者一个平面进行分割的，而根据维基
百科的定义，线性函数是指：线性函数是只拥有一个参数的一阶多项式函数。所以需要引进
非线性函数用来解决线性函数的不足。这种位于层中的非线性函数被称为激励函数。
</p>

<p>
从另一个角度，如果没有激励函数，那该网络仅仅能表达线性处理，这样即使具有更多的隐
藏层，其功能都可以用单层的神经网络进行实现，表明，如果没有激励函数为模型提供非线
性转化，那隐藏层是没有作用的。
</p>

<p>
激励函数与损失函数：激励函数用于提供非线性功能，而损失函数用于计算预测结果与实际
结果之间的差异。
</p>

<p>
激励函数作为一个神经元，用于对输入变量进行处理，事实上任何数学函数都可以作为激励函数。
常见的激活函数有以下几个：
</p>
</div>
</div>
<div id="outline-container-orgdf07cc3" class="outline-3">
<h3 id="orgdf07cc3">Sigmoid</h3>
<div class="outline-text-3" id="text-orgdf07cc3">
<p>
非线性函数，取值范围为[0, 1], \(\sigma(x) = \frac{1}{1 + exp(-x)}\) 主要将一个值
归一化，即压缩到0与1之间，根据公式可以看出，大的负数值将会被求值为0，而大的正数
值将会被求值为1。
</p>
<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #6c71c4;">f_sigmoid</span> = <span style="color: #859900;">lambda</span> x: 1.0 / (1.0 + np.exp(-x))
<span style="color: #859900;">def</span> <span style="color: #268bd2;">f_plot</span>(f, x):
    <span style="color: #6c71c4;">y</span> = <span style="color: #268bd2;">list</span>(<span style="color: #268bd2;">map</span>(f, x))
    plt.style.use(<span style="color: #2aa198;">'ggplot'</span>)
    plt.plot(x, y, <span style="color: #2aa198;">'r-'</span>)
    plt.plot([0.0, 0.0], [<span style="color: #268bd2;">min</span>(y) -1, <span style="color: #268bd2;">max</span>(y)+1], <span style="color: #2aa198;">'b-'</span>)
    plt.plot([-10.0, 10.0], [0.0, 0.0], <span style="color: #2aa198;">'b-'</span>)
    plt.xlabel(<span style="color: #2aa198;">'x'</span>)
    plt.ylabel(<span style="color: #2aa198;">'y'</span>)

<span style="color: #6c71c4;">x</span> = np.arange(-10, 10, 0.001)
f_plot(f_sigmoid, x)
</pre>
</div>


<figure>
<img src="./images/cifar-on-ann-393527.png" alt="cifar-on-ann-393527.png">

</figure>
</div>
<div id="outline-container-org4903870" class="outline-4">
<h4 id="org4903870">缺点：</h4>
<div class="outline-text-4" id="text-org4903870">
<p>
在 sigmoid 的两端即位于0或者1上的点的梯度都是0(也称为：饱和)，如果一开始所给予过大
的权重，将会直接被判断为1，将不会被学习。函数输出的结果不是以0为中心化的，而且都
是为大于0。
</p>
</div>
</div>
</div>
<div id="outline-container-orgee228bf" class="outline-3">
<h3 id="orgee228bf">tanh(logistic)</h3>
<div class="outline-text-3" id="text-orgee228bf">
<p>
非线性函数，取值范围为[-1, 1]，Sigmod变体，但是为0中心化的，\(tanh(x) =
2\sigma(2x) - 1\)
</p>
<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #6c71c4;">f_tanh</span> = <span style="color: #859900;">lambda</span> x: 2.0 * f_sigmoid(2.0 * x) - 1.0
f_plot(f_tanh, x)
</pre>
</div>


<figure>
<img src="./images/cifar-on-ann-891349.png" alt="cifar-on-ann-891349.png">

</figure>
</div>
</div>

<div id="outline-container-org088268b" class="outline-3">
<h3 id="org088268b">修正线性单元(ReLU)</h3>
<div class="outline-text-3" id="text-org088268b">
<p>
ReLU(Rectified Linear Unit)函数表示成\(ReLU(x) = max(0, x)\)。从斜率的角度看就是，
当x大于0,斜率为1,否则为0。因为ReLU的缺点，所以在使用时，需要小心模型学习速率，如
果很关心学习的速率，可以尝试Leaky ReLU或者Maxout。
</p>
<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #6c71c4;">f_relu</span> = <span style="color: #859900;">lambda</span> x: x <span style="color: #859900;">if</span> x &gt; 0 <span style="color: #859900;">else</span> 0
f_plot(f_relu, x)
</pre>
</div>


<figure>
<img src="./images/cifar-on-ann-723822.png" alt="cifar-on-ann-723822.png">

</figure>
</div>

<div id="outline-container-org3cce919" class="outline-4">
<h4 id="org3cce919">优点：</h4>
<div class="outline-text-4" id="text-org3cce919">
<p>
在随机梯度下降中，比tanh/Sigmod的收敛速度更快，并由于其是线性的，不会出现饱和现
象(指当达到一定的阀值后，值不会发生改变，如Sigmod中的，当达到一定程度后，很大的
数求值为1,很小的数求值为0，位于两点的梯度都为0，造成梯度消失(kill gradient)。与
tanh/Sigmod相比，计算量更小，只需要判断，而tanh/Sigmod需要计算指数。
</p>
</div>
</div>
<div id="outline-container-org0a6cd6a" class="outline-4">
<h4 id="org0a6cd6a">缺点：</h4>
<div class="outline-text-4" id="text-org0a6cd6a">
<p>
ReLU很脆弱，如果当具有一个很大的梯度通过一个ReLU神经元时，将会导致这个神经元“死
掉”。这是因为大的梯度，导致权重更新的步伐过快，将可能导致可以通过调整更低的学习速率进行解决。
</p>
</div>
</div>
</div>
<div id="outline-container-org3cc8119" class="outline-3">
<h3 id="org3cc8119">泄漏ReLU(leaky ReLU)</h3>
<div class="outline-text-3" id="text-org3cc8119">
<p>
为了解决ReLU“死掉”问题而设计，当 x&lt;0 时，将给予一个微小的数，而不是0。就如，当
\(x<0 f(x) = ax\) 当 \(x>=0 f(x)=x\), 其中a代表一个常数，在一些方面可以取得很好
的结果，但一些方面结果并不令人满意。
</p>
<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #6c71c4;">f_leaky_relu</span> = <span style="color: #859900;">lambda</span> x: x <span style="color: #859900;">if</span> x &gt;= 0 <span style="color: #859900;">else</span> 0.25*x
f_plot(f_leaky_relu, x)
</pre>
</div>


<figure>
<img src="./images/cifar-on-ann-495479.png" alt="cifar-on-ann-495479.png">

</figure>
</div>
</div>

<div id="outline-container-org4d1f99b" class="outline-3">
<h3 id="org4d1f99b">Maxout</h3>
<div class="outline-text-3" id="text-org4d1f99b">
<p>
将多个激励函数进行合并，表达式为: \(max(F_1, F_2, ...)\) ，当后面的\(F_2, ...,
F_n\)为0时退化为ReLU函数，防止梯度消失(饱和)， 有避免ReLu的缺点(因为梯度过大导致
神经元“死掉”)，但这样，其对于每一个神经元必须需要传递两个参数以上的变量。
</p>
<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #6c71c4;">f_maxout</span> = <span style="color: #859900;">lambda</span> x: f_sigmoid(x) <span style="color: #859900;">if</span> f_sigmoid(x) &gt; f_relu(x) <span style="color: #859900;">else</span> f_relu(x)
f_plot(f_maxout, x)
</pre>
</div>


<figure>
<img src="./images/cifar-on-ann-890421.png" alt="cifar-on-ann-890421.png">

</figure>
</div>
</div>
</div>
<div id="outline-container-org6ce96fe" class="outline-2">
<h2 id="org6ce96fe">前向传播</h2>
<div class="outline-text-2" id="text-org6ce96fe">
<p>
前向传播就是平时看到的传播模式，就是一个一个接着往下传播。简单的前向传播实现，主
要用于理解前向传播的思想。
</p>
</div>
<div id="outline-container-orgf156b52" class="outline-3">
<h3 id="orgf156b52">前向传播算法</h3>
<div class="outline-text-3" id="text-orgf156b52">
<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #859900;">def</span> <span style="color: #268bd2;">forward_pass</span>(input_volumes, input_weights, input_biases, stride=1, zero_padding=0):
    <span style="color: #35a69c;">'''input_array(num, channel, width, height) &#20998;&#21035;&#23545;&#24212;&#22270;&#29255;&#30340;&#25968;&#37327;&#65292;&#22270;&#29255;&#30340;&#23618;&#25968;&#65292;&#23485;&#24230;&#65292;&#39640;&#24230;</span>
<span style="color: #35a69c;">    input_weights(num, channel, width, height) &#20998;&#21035;&#23545;&#24212;&#36807;&#28388;&#22120;&#30340;&#20010;&#25968;&#65292;channel&#65292;&#23485;&#24230;&#65292;&#39640;&#24230;</span>
<span style="color: #35a69c;">    channel &#19982; depth &#24182;&#19981;&#19968;&#26679;&#65292;&#21069;&#32773;&#20195;&#34920;&#21333;&#20010;&#26679;&#26412;&#20013;&#30340;Z&#36724;&#65292;&#32780;depth&#20195;</span>
<span style="color: #35a69c;">    &#34920;&#21367;&#31215;&#23618;&#30340;Z&#36724;&#65292;&#21363;&#37319;&#38598;&#22120;&#30340;&#20010;&#25968;&#20063;&#31216;&#20026;&#20869;&#26680;&#30340;&#20010;&#25968;&#12290;</span>
<span style="color: #35a69c;">    '''</span>
    <span style="color: #6c71c4;">x_num</span>, <span style="color: #6c71c4;">x_channel</span>, <span style="color: #6c71c4;">x_height</span>, <span style="color: #6c71c4;">x_width</span> = input_volumes.shape
    <span style="color: #6c71c4;">f_num</span>, <span style="color: #6c71c4;">_</span>, <span style="color: #6c71c4;">f_height</span>, <span style="color: #6c71c4;">f_width</span> = input_weights.shape
    <span style="color: #6c71c4;">out_height</span> = (x_height - f_height + 2*zero_padding) // stride + 1
    <span style="color: #6c71c4;">out_width</span> = (x_width - f_width + 2*zero_padding) // stride + 1

    <span style="color: #6c71c4;">X</span> = np.pad(input_volumes, ((0, 0), (0, 0), (zero_padding, zero_padding), (zero_padding, zero_padding)),
               <span style="color: #2aa198;">"constant"</span>, constant_values=0)

    <span style="color: #405A61;"># </span><span style="color: #405A61;">&#27599;&#19968;&#20010;&#37319;&#38598;&#22120;&#21482;&#20250;&#20135;&#29983;&#19968;&#20010;&#20108;&#32500;&#30340;&#25968;&#32452;</span>
    <span style="color: #6c71c4;">dout</span> = np.zeros((x_num, f_num, out_height, out_width))
    <span style="color: #405A61;"># </span><span style="color: #405A61;">&#23545;&#26679;&#26412;&#36845;&#20195;&#65292;&#21363;&#23545;&#27599;&#19968;&#24352;&#22270;&#29255;&#36827;&#34892;&#36845;&#20195;</span>
    <span style="color: #859900;">for</span> n <span style="color: #859900;">in</span> <span style="color: #268bd2;">range</span>(x_num):
        <span style="color: #405A61;"># </span><span style="color: #405A61;">&#23545;&#22810;&#20010;&#37319;&#38598;&#22120;&#36827;&#34892;&#36845;&#20195;&#37319;&#38598;</span>
        <span style="color: #859900;">for</span> f <span style="color: #859900;">in</span> <span style="color: #268bd2;">range</span>(f_num):
            <span style="color: #859900;">for</span> y <span style="color: #859900;">in</span> <span style="color: #268bd2;">range</span>(0, out_height):
                <span style="color: #859900;">for</span> x <span style="color: #859900;">in</span> <span style="color: #268bd2;">range</span>(0, out_width):
                    <span style="color: #405A61;"># </span><span style="color: #405A61;">&#21033;&#29992;&#36755;&#20986;&#30340;&#32500;&#24230;&#65292;&#21453;&#25512;&#37319;&#38598;&#30340;&#21306;&#22495;</span>
                    <span style="color: #6c71c4;">dout</span>[n, f, y, x] = np.<span style="color: #268bd2;">sum</span>(
                        X[n, :, y*stride : y*stride + f_height, x*stride : x*stride + f_width] * input_weights[f]
                    ) + input_biases[f]
    <span style="color: #6c71c4;">cache</span> = (input_volumes, input_weights, input_biases, stride, zero_padding)
    <span style="color: #859900;">return</span> dout, cache
</pre>
</div>
</div>
</div>
<div id="outline-container-org0c648bf" class="outline-3">
<h3 id="org0c648bf">测试数据</h3>
<div class="outline-text-3" id="text-org0c648bf">
<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #6c71c4;">x_shape</span> = (2, 3, 4, 4)
<span style="color: #6c71c4;">w_shape</span> = (3, 3, 4, 4)
<span style="color: #6c71c4;">x</span> = np.linspace(-0.1, 0.5, num=np.prod(x_shape)).reshape(x_shape)
<span style="color: #6c71c4;">w</span> = np.linspace(-0.2, 0.3, num=np.prod(w_shape)).reshape(w_shape)
<span style="color: #6c71c4;">b</span> = np.linspace(-0.1, 0.2, num=3)

<span style="color: #405A61;"># </span><span style="color: #405A61;">&#27491;&#30830;&#30340;&#31572;&#26696;</span>
<span style="color: #6c71c4;">correct_out</span> = np.array([[[[-0.08759809, -0.10987781],
                          [-0.18387192, -0.2109216 ]],
                         [[ 0.21027089,  0.21661097],
                          [ 0.22847626,  0.23004637]],
                         [[ 0.50813986,  0.54309974],
                          [ 0.64082444,  0.67101435]]],
                        [[[-0.98053589, -1.03143541],
                          [-1.19128892, -1.24695841]],
                         [[ 0.69108355,  0.66880383],
                          [ 0.59480972,  0.56776003]],
                         [[ 2.36270298,  2.36904306],
                          [ 2.38090835,  2.38247847]]]])
<span style="color: #405A61;"># </span><span style="color: #405A61;">&#35745;&#31639;&#30456;&#23545;&#35823;&#24046;</span>
<span style="color: #6c71c4;">dout</span>, <span style="color: #6c71c4;">_</span> = forward_pass(x, w, b, 2, 1)
<span style="color: #859900;">print</span>(<span style="color: #2aa198;">"relative_error: "</span>, relative_error(dout, correct_out))
</pre>
</div>

<pre class="example">
relative_error:  2.2121476417505994e-08

</pre>
</div>
</div>
</div>
<div id="outline-container-orgc43b87e" class="outline-2">
<h2 id="orgc43b87e">反向传播(误差反向传播)</h2>
<div class="outline-text-2" id="text-orgc43b87e">
<p>
<b>误差</b> 从输出节点反向传播到输入的节点，是一种需要与 <b>最优化</b> 算法结合使用的方法。
该方法对 <b>网络中所有的权重计算损失函数的梯度</b> 。这个梯度会反馈给最优化算法，用来
更新权重值，一最小化损失函数。
</p>

<p>
反向传播要求每一个 <b>输入值</b> 对应的一个渴望的 <b>输出值</b> 用来计算损失函数的梯度。
</p>

<p>
反向传播一般具有三个层，分别为输入层、隐藏层、输出层。其中通过正向的传播计算最后
的预测值，通过与期望值进行比较，计算误差(一般平方误差)，而通过梯度下降的方法寻找
最低的权重值，以至于最后的误差值处于极小值。
</p>
</div>
<div id="outline-container-org7701ad9" class="outline-3">
<h3 id="org7701ad9">简单的反向传播实现</h3>
<div class="outline-text-3" id="text-org7701ad9">
<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #859900;">def</span> <span style="color: #268bd2;">backward_pass</span>(dout, cache):
    <span style="color: #35a69c;">'''&#36825;&#37324;dout&#20026;&#19968;&#20010;&#28212;&#26395;&#36755;&#20986;&#25968;&#32452;&#65292;cache&#20026;&#20013;&#20855;&#26377;input_volumes, input_weights,</span>
<span style="color: #35a69c;">    input_baises, stride, zero_padding'''</span>
    <span style="color: #6c71c4;">X</span>, <span style="color: #6c71c4;">W</span>, <span style="color: #6c71c4;">B</span>, <span style="color: #6c71c4;">S</span>, <span style="color: #6c71c4;">P</span> = cache
    <span style="color: #6c71c4;">x_num</span>, <span style="color: #6c71c4;">x_channel</span>, <span style="color: #6c71c4;">x_height</span>, <span style="color: #6c71c4;">x_width</span> = X.shape
    <span style="color: #6c71c4;">w_num</span>, <span style="color: #6c71c4;">_</span>, <span style="color: #6c71c4;">w_height</span>, <span style="color: #6c71c4;">w_width</span> = W.shape

    <span style="color: #405A61;"># </span><span style="color: #405A61;">&#20351;&#29992;np.pad&#29983;&#25104;zeros padding&#21518;&#30340;&#25968;&#32452;&#65292;X&#20855;&#26377;&#22235;&#20010;&#32500;&#24230;&#65292;&#32780;&#25105;&#20204;&#21482;&#38656;&#35201;&#23545;</span>
    <span style="color: #405A61;"># </span><span style="color: #405A61;">&#26368;&#37324;&#38754;&#20004;&#20010;&#32500;&#24230;&#36827;&#34892;padding&#65292;&#22240;&#27492;&#21069;&#38754;&#20004;&#20010;&#35774;&#32622;&#25104;(0,0)&#65292;&#32780;&#21518;&#20004;&#20010;&#32500;&#24230;(P,P)&#34920;&#31034;&#22312;&#36825;&#20010;</span>
    <span style="color: #405A61;"># </span><span style="color: #405A61;">&#21069;&#38754;&#28155;&#21152;P&#20010;&#25351;&#23450;constant padding&#65292;&#32780;&#21518;&#38754;&#20063;&#28155;&#21152;P&#20010;constant padding&#12290;</span>
    <span style="color: #6c71c4;">X_pad</span> = np.pad(X, ((0, 0), (0, 0), (P, P), (P, P)), <span style="color: #2aa198;">"constant"</span>, constant_values=0)
    <span style="color: #6c71c4;">o_Xpad</span> = np.zeros_like(X_pad)

    <span style="color: #405A61;"># </span><span style="color: #405A61;">&#35745;&#31639;&#32467;&#26524;&#25968;&#32452;&#30340;&#32500;&#24230;</span>
    <span style="color: #6c71c4;">o_height</span> = (x_height - w_height + 2 * P) // S + 1
    <span style="color: #6c71c4;">o_width</span> = (x_width - w_width + 2 * P) // S + 1

    <span style="color: #405A61;"># </span><span style="color: #405A61;">&#36755;&#20986;&#32467;&#26524;</span>
    <span style="color: #6c71c4;">o_X</span> = np.zeros_like(X)
    <span style="color: #6c71c4;">o_W</span> = np.zeros_like(W)
    <span style="color: #6c71c4;">o_B</span> = np.zeros_like(B)

    <span style="color: #859900;">for</span> n <span style="color: #859900;">in</span> <span style="color: #268bd2;">range</span>(x_num):
        <span style="color: #859900;">for</span> f <span style="color: #859900;">in</span> <span style="color: #268bd2;">range</span>(w_num):
            <span style="color: #405A61;"># </span><span style="color: #405A61;">&#20559;&#24046;&#30340;&#20010;&#25968;&#19982;&#36807;&#28388;&#22120;&#30340;&#20010;&#25968;&#30456;&#21516;</span>
            <span style="color: #6c71c4;">o_B</span>[f] += dout[n, f].<span style="color: #268bd2;">sum</span>()
            <span style="color: #405A61;"># </span><span style="color: #405A61;">&#26681;&#25454;&#36755;&#20986;&#32500;&#24230;&#65292;&#25512;&#20986;&#37319;&#38598;&#30340;&#20301;&#32622;&#65292;&#23545;padding&#21518;&#30340;&#30697;&#38453;&#36827;&#34892;&#32034;&#24341;</span>
            <span style="color: #859900;">for</span> y <span style="color: #859900;">in</span> <span style="color: #268bd2;">range</span>(0, o_height):
                <span style="color: #859900;">for</span> x <span style="color: #859900;">in</span> <span style="color: #268bd2;">range</span>(0, o_width):
                    <span style="color: #405A61;"># </span><span style="color: #405A61;">&#23558;&#21069;&#21521;&#20256;&#25773;&#32467;&#26524;&#20013;&#23545;&#24212;&#30340;&#20540; &#20056;&#20197; &#25152;&#37319;&#38598;&#30340;&#21306;&#22495; &#32047;&#21152;&#21040;&#26435;&#37325;&#30697;&#38453;&#20013;</span>
                    <span style="color: #405A61;"># </span><span style="color: #405A61;">&#26126;&#26174;&#22320;&#65292;&#22914;&#26524;&#36755;&#20986;&#30697;&#38453;&#20013;&#23545;&#24212;&#30340;&#20540;&#20026;0,&#21017;&#26435;&#37325;&#30697;&#38453;&#20445;&#25345;&#19981;&#21464;&#12290;</span>
                    <span style="color: #6c71c4;">o_W</span>[f] += X_pad[n, :, y*S : y*S+w_height, x*S : x*S+w_width] * dout[n, f, y, x]
                    <span style="color: #405A61;"># </span><span style="color: #405A61;">&#23545;&#21407;&#22987;&#30340;&#25968;&#25454;&#36827;&#34892;&#26356;&#26032;&#65292;&#21453;&#21521;&#26356;&#26032;&#25968;&#25454;</span>
                    <span style="color: #6c71c4;">o_Xpad</span>[n, :, y*S : y*S+w_height, x*S : x*S+w_width] += W[f] * dout[n, f, y, x]
    <span style="color: #6c71c4;">o_X</span> = o_Xpad[:, :, P:P+x_height, P:P+x_width]
    <span style="color: #859900;">return</span> o_X, o_W, o_B
</pre>
</div>
</div>
</div>
</div>
<div id="outline-container-orgf1e9650" class="outline-2">
<h2 id="orgf1e9650">通过卷积处理图片</h2>
<div class="outline-text-2" id="text-orgf1e9650">
<p>
读取图片，在原来的 <code>scipy</code> 包中，可以使用 <code>scipy.misc.imread</code> 来对图片进行读取，
而后来的 <code>scipy</code> 包中可以使用 <code>scipy.imageio.imread</code> 来取代，但是
<code>scipy.imageio.imread</code> 返回的数组类型是 <code>scipy.imageio.core.util.Array</code> ，而不是
常用的 <code>numpy.ndarray</code> 数组，因此可以使用 <code>matplotlib.pyplot.imread</code> 对图片进行读取并返
回 <code>numpy.ndarray</code> 格式。但是最新的 <code>scipy</code> 版本中，也没有了 <code>imageio</code> 模块；而
 <code>matplotlib.pyplot.imread</code> 支持的格式并不是很多，需要可以使用 <code>pillow</code> 。
</p>
</div>
<div id="outline-container-org59898b4" class="outline-3">
<h3 id="org59898b4">图片预览</h3>
<div class="outline-text-3" id="text-org59898b4">
<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #859900;">from</span> PIL <span style="color: #859900;">import</span> Image
<span style="color: #6c71c4;">kieen</span> = Image.<span style="color: #268bd2;">open</span>(<span style="color: #2aa198;">"./images/cifar-on-ann-cat.jpg"</span>)
<span style="color: #405A61;"># </span><span style="color: #405A61;">kieen = plt.imread("./images/cifar-on-ann-cat.jpg")</span>
<span style="color: #6c71c4;">puppy</span> = Image.<span style="color: #268bd2;">open</span>(<span style="color: #2aa198;">"./images/cifar-on-ann-dog.jpg"</span>)
plt.figure(figsize=(10.0, 8.0))
plt.subplot(1, 2, 1)
plt.imshow(kieen)
plt.xticks([])
plt.yticks([])
plt.subplot(1, 2, 2)
plt.imshow(puppy)
plt.xticks([])
plt.yticks([])
plt.show()
</pre>
</div>


<figure>
<img src="./images/cifar-on-ann-834866.png" alt="cifar-on-ann-834866.png">

</figure>
</div>
</div>

<div id="outline-container-org71c6cb1" class="outline-3">
<h3 id="org71c6cb1">裁剪</h3>
<div class="outline-text-3" id="text-org71c6cb1">
<p>
由于图片分辨率为1277x1920不是方阵，这里先对图片进行裁剪成方阵。
</p>
<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #6c71c4;">kieen_cropped</span> = kieen.crop((0, 0, kieen.size[0], kieen.size[0]))
<span style="color: #6c71c4;">puppy_cropped</span> = puppy.crop((0, 0, puppy.size[0], puppy.size[0]))
plt.subplot(1, 2, 1)
plt.imshow(kieen_cropped)
plt.axis(<span style="color: #2aa198;">'off'</span>)
plt.subplot(1, 2, 2)
plt.imshow(puppy_cropped)
plt.axis(<span style="color: #2aa198;">'off'</span>)
</pre>
</div>


<figure>
<img src="./images/cifar-on-ann-689444.png" alt="cifar-on-ann-689444.png">

</figure>
</div>
</div>

<div id="outline-container-org8a11818" class="outline-3">
<h3 id="org8a11818">重设大小</h3>
<div class="outline-text-3" id="text-org8a11818">
<p>
选择一个更小的图片进行试验。
</p>
<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #6c71c4;">img_size</span> = 200
<span style="color: #6c71c4;">kieen_small</span> = kieen.resize((img_size, img_size))
<span style="color: #6c71c4;">puppy_small</span> = puppy.resize((img_size, img_size))
<span style="color: #6c71c4;">kieen_array</span> = np.array(kieen_small)
<span style="color: #6c71c4;">puppy_array</span> = np.array(puppy_small)

<span style="color: #6c71c4;">x</span> = np.zeros((2, 3, img_size, img_size))
<span style="color: #405A61;"># </span><span style="color: #405A61;">&#23558;RGB&#32500;&#25918;&#22312;&#21069;&#38754;</span>
<span style="color: #6c71c4;">x</span>[0, :, :, :] = kieen_array.transpose((2, 0, 1))
<span style="color: #6c71c4;">x</span>[1, :, :, :] = puppy_array.transpose((2, 0, 1))
</pre>
</div>
</div>
</div>
<div id="outline-container-orgccbfbcc" class="outline-3">
<h3 id="orgccbfbcc">生成权重矩阵（过滤器）</h3>
<div class="outline-text-3" id="text-orgccbfbcc">
<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #405A61;"># </span><span style="color: #405A61;">&#19968;&#20849;&#19977;&#20010;&#36807;&#28388;&#22120;&#65292;&#27599;&#19968;&#20010;&#20026;3x3x3</span>
<span style="color: #6c71c4;">w</span> = np.zeros((2, 3, 3, 3))

<span style="color: #405A61;"># </span><span style="color: #405A61;">&#31532;&#19968;&#20010;&#65292;&#21033;&#29992;&#30697;&#38453;&#23545;&#22270;&#29255;&#36827;&#34892;&#36716;&#21464;</span>
<span style="color: #6c71c4;">w</span>[0, 0, :, :] = [[0, 0, 0], [0, 0.3, 0], [0, 0, 0]] <span style="color: #405A61;"># </span><span style="color: #405A61;">red</span>
<span style="color: #6c71c4;">w</span>[0, 1, :, :] = [[0, 0, 0], [0, 0.6, 0], [0, 0, 0]] <span style="color: #405A61;"># </span><span style="color: #405A61;">green</span>
<span style="color: #6c71c4;">w</span>[0, 2, :, :] = [[0, 0, 0], [0, 0.1, 0], [0, 0, 0]] <span style="color: #405A61;"># </span><span style="color: #405A61;">blue</span>

<span style="color: #6c71c4;">w</span>[1, 2, :, :] = [[1, 2, 1], [0, 0, 0], [-1, -2, -1]] <span style="color: #405A61;"># </span><span style="color: #405A61;">blue</span>
<span style="color: #405A61;"># </span><span style="color: #405A61;">&#20559;&#24046;</span>
<span style="color: #6c71c4;">b</span> = np.array([0, 128])
</pre>
</div>
</div>
</div>
<div id="outline-container-org842bd12" class="outline-3">
<h3 id="org842bd12">卷积操作</h3>
<div class="outline-text-3" id="text-org842bd12">
<div class="org-src-container">
<pre class="src src-jupyter-python"><span style="color: #6c71c4;">out</span>, <span style="color: #6c71c4;">_</span> = forward_pass(x, w, b, 1, 1)

<span style="color: #859900;">def</span> <span style="color: #268bd2;">imshow_helper</span>(img, normalize=<span style="color: #d33682;">True</span>):
    <span style="color: #35a69c;">'''predigest the plot command'''</span>
    <span style="color: #405A61;"># </span><span style="color: #405A61;">&#24402;&#19968;&#21270;</span>
    <span style="color: #859900;">if</span> normalize:
        <span style="color: #6c71c4;">img_max</span>, <span style="color: #6c71c4;">img_min</span> = np.<span style="color: #268bd2;">max</span>(img), np.<span style="color: #268bd2;">min</span>(img)
        <span style="color: #6c71c4;">img</span> = 225.0 * (img - img_min) / (img_max - img_min)
    plt.imshow(img.astype(<span style="color: #2aa198;">'uint8'</span>))
    plt.gca().axis(<span style="color: #2aa198;">'off'</span>)

plt.figure(figsize=(15, 10))
<span style="color: #405A61;"># </span><span style="color: #405A61;">kieen</span>
plt.subplot(2, 4, 1)
imshow_helper(kieen_array, normalize=<span style="color: #d33682;">False</span>)
plt.title(<span style="color: #2aa198;">'original'</span>)
plt.subplot(2, 4, 2)
imshow_helper(kieen_array, normalize=<span style="color: #d33682;">True</span>)
plt.title(<span style="color: #2aa198;">'normalize'</span>)
plt.subplot(2, 4, 3)
imshow_helper(out[0, 0])
plt.title(<span style="color: #2aa198;">'grayscale'</span>)
plt.subplot(2, 4, 4)
imshow_helper(out[0, 1])
plt.title(<span style="color: #2aa198;">'edges'</span>)

<span style="color: #405A61;"># </span><span style="color: #405A61;">puppy</span>
plt.subplot(2, 4, 5)
imshow_helper(puppy_array, normalize=<span style="color: #d33682;">False</span>)
plt.subplot(2, 4, 6)
imshow_helper(puppy_array, normalize=<span style="color: #d33682;">True</span>)
plt.subplot(2, 4, 7)
imshow_helper(out[1, 0])
plt.subplot(2, 4, 8)
imshow_helper(out[1, 1])
plt.show()
</pre>
</div>


<figure>
<img src="./images/cifar-on-ann-321220.png" alt="cifar-on-ann-321220.png">

</figure>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<footer class="footer">
      <!-- Footer Definition -->
   </footer>

  <!-- Google Analytics Js --><!-- Disqua JS -->
</div>

</div>
<div class="col"></div></div>
</div>
</body>
</html>
